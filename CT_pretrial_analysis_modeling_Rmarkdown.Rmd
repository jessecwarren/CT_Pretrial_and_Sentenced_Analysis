---
title: "CT_pretrial_analysis_modeling"
author: "Jesse Warren"
date: "5/29/2020"
output: html_document
editor_options: 
  chunk_output_type: console
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = FALSE)

library(janitor)
library(data.table)
library(RSocrata)
library(ggplot2)
library(ggrepel)
library(extrafont)
library(ggthemes)
library(reshape)
library(grid)
library(scales)
library(RColorBrewer)
library(gridExtra)
library(viridis)
library(hexbin)
library(sandwich)
library(stargazer)
library(lubridate)
library(stringdist)
library(scales)
library(cluster)    
library(factoextra)
library(fuzzyjoin)
library(tidymodels)
library(modeldata)
library(ranger)
library(sf)
library(ggpubr)
library(scales)
options(scipen=999)
library(tidyverse)


#load functions from helper files
source("Helper_functions/Data_loading_and_cleaning_functions.R")
```



```{r load pretrial data}
#2 options to load data:
  #1. straight from online open data repository for most up to date data
  #2. from local files (downloaded 5/2/2020)

#option 1.
#load pretrial data from Connecticut open data site  
pretrial_data_URL <- "https://data.ct.gov/Public-Safety/Accused-Pre-Trial-Inmates-in-Correctional-Faciliti/b674-jy6w"
#CT__analysis_pretrial_raw <- read.socrata((CT_pretrial_data_URL))

#option 2.
#load from local file, in Data/ folder
pretrial_raw <- fread("Data/Accused_Pre-Trial_Inmates_in_Correctional_Facilities.csv")

#fix race names using helper function
pretrial_raw <- fix_race_names_function(pretrial_raw)

#clean names, set variable types, fix dates using helper function
pretrial_raw <- pretrial_names_variable_types_dates_cleaning_function(pretrial_raw)

#create clean df to work with from here on out
pretrial_clean <- pretrial_raw

#remove inconsistently coded race and gender observations
pretrial_clean <- remove_inconsistently_coded_people_function(pretrial_clean)
```

```{r get one observation per charge for the pretrial detention dataset}
#Create new df that will have only one observation per charge
pretrial_clean_1charge <- pretrial_clean

#remove excess whitespace in offense variable
pretrial_clean_1charge <- pretrial_clean_1charge %>% 
  mutate(offense = str_squish(offense))

#Make a new variable for length of time in jail for person-admission
pretrial_clean_1charge <- pretrial_clean_1charge %>% 
   group_by(identifier, pretrial_latest_admission_date) %>%
   mutate(pretrial_detention_length = n())

#Generate indicators for date being 1)most recent download date, 2)earliest possible download date
most_recent_pretrial_download_date_in_dataset <- max(pretrial_clean_1charge$pretrial_download_date)
earliest_pretrial_download_date_in_dataset <- min(pretrial_clean_1charge$pretrial_download_date)

#this checks and sees if their pretrial download date is the most recent one available, indicating they are still in jail. max.still_in_jail tells is 1 if they are still in jail as of this data download
pretrial_clean_1charge$still_in_jail <- as.numeric(pretrial_clean_1charge$pretrial_download_date == most_recent_pretrial_download_date_in_dataset)
pretrial_clean_1charge <- pretrial_clean_1charge %>% 
   group_by(identifier, pretrial_latest_admission_date) %>%
   mutate(still_in_jail = max(still_in_jail),
          earliest_pretrial_download_date = min(pretrial_download_date))

#now just get one observation per charge. note that this takes the bond amount on the last day the person was in pretrial detention as their bond amount - for some observations this changes throughout the dataset. however the most recent observation is likely the most accurate one.
pretrial_clean_1charge <- pretrial_clean_1charge %>% 
  arrange(desc(pretrial_download_date)) %>% 
  group_by(identifier, pretrial_latest_admission_date, offense) %>% 
  slice(1) %>% 
  dplyr::rename(latest_pretrial_download_date = pretrial_download_date)

#add column with number of times each identifier is in dataset. note that some people have multiple observations because they were either:
  #arrested for multiple offenses at the same time
  #arrested different times for different offenses
pretrial_clean_1charge <- pretrial_clean_1charge %>% 
  group_by(identifier) %>% 
  mutate(number_pretrial_detention_charges = n())

#exclude people who exit the dataset in the first 60 days of recorded data (what should be the max time in pretrial detention). we dont observe their entire time in dataset at beginning, as they might have been in pretrial detention before data started being collected
pretrial_clean_1charge <- pretrial_clean_1charge %>% 
  filter(latest_pretrial_download_date > (60 + earliest_pretrial_download_date_in_dataset))

```

```{r create variables for modeling}
#create a new modeling df
pretrial_modeling_df <- pretrial_clean_1charge

#only dplyr::select relevant variables
pretrial_modeling_df <- pretrial_modeling_df %>% 
  dplyr::dplyr::select(identifier,
         race,
         gender,
         pretrial_age,
         bond_amount,
         offense,
         pretrial_detention_length,
         still_in_jail,
         pretrial_detainer,
         number_pretrial_detention_charges,
         pretrial_latest_admission_date,
         earliest_pretrial_download_date,
         latest_pretrial_download_date)

#create variable ordering each pretrial detention charge
pretrial_modeling_df <- pretrial_modeling_df %>% 
  group_by(identifier) %>%
  arrange(earliest_pretrial_download_date) %>% 
  mutate(charge_count = 1:n()) %>% 
  dplyr::select(1:number_pretrial_detention_charges, charge_count, everything())

#create indicator noting the person was arrested more than once
pretrial_modeling_df <- pretrial_modeling_df %>% 
  group_by(identifier) %>%
  mutate(multiple_charges = ifelse(number_pretrial_detention_charges > 1, 1, 0)) %>% 
  dplyr::select(1:charge_count, multiple_charges, everything())
  
#calculate time between each charge
pretrial_modeling_df <- pretrial_modeling_df %>% 
  group_by(identifier) %>%
  arrange(earliest_pretrial_download_date) %>% 
  mutate(time_since_last_charge = earliest_pretrial_download_date - lag(earliest_pretrial_download_date)) %>% 
  dplyr::select(1:multiple_charges, time_since_last_charge, everything())

#create indicator noting whether person was arrested within year of previous charge. dont count charges if they occur on the same date
pretrial_modeling_df <- pretrial_modeling_df %>% 
  group_by(identifier) %>%
  mutate(arrested_again_within_year = lead(case_when(time_since_last_charge >= 1 & time_since_last_charge <= 365 ~ 1,
                                                  TRUE ~ 0))) %>% 
  mutate(arrested_again_within_year = replace(arrested_again_within_year, is.na(arrested_again_within_year), 0)) %>% 
  dplyr::select(1:time_since_last_charge, arrested_again_within_year, everything())


#ungroup
pretrial_modeling_df <- pretrial_modeling_df %>% 
  ungroup()
```

```{r conduct cluser analysis}
#conduct cluster analysis, excluding those with life sentences
pretrial_modeling_df_cluster <- pretrial_modeling_df %>% 
  ungroup() %>% 
  dplyr::select(pretrial_age, pretrial_detention_length, bond_amount, number_pretrial_detention_charges)

fviz_nbclust(head(pretrial_modeling_df_cluster, 10000), kmeans, method = "silhouette")

k1 <- kmeans(pretrial_modeling_df_cluster, centers = 2)

fviz_cluster(k1, data = pretrial_modeling_df_cluster)
```

```{r create model to try to predict whether person will be charged multiple times}
#questions 
  # do i need one row per identifier?
#The goal here is to predict whether someone will have subsequent arrests within the same year after their pretrial detention
#set arrested_again_within_year, the value we're trying to predict, to be a 0/1 factor
pretrial_modeling_df_ml <- pretrial_modeling_df %>% 
  mutate(arrested_again_within_year = as.factor(arrested_again_within_year))


#summarize arrested_again_within_year to view
pretrial_modeling_df_ml %>% 
  count(arrested_again_within_year) %>% 
  mutate(prop = n/sum(n))
  
#set seed
set.seed(29)

#split data into training and test, using a 4/5 proportion
data_split <- initial_split(pretrial_modeling_df_ml, prop = 4/5)
train_data <- training(data_split)
test_data <- testing(data_split)

#create recipe for model - Note: I dont use offense because it has so many levels it takes the model a long time to run
number_charges_recipe <- 
  recipe(arrested_again_within_year ~ race + gender + offense + pretrial_age + bond_amount + pretrial_detention_length + charge_count + identifier, data = train_data) %>% #set outcome & predicter variables
  update_role(identifier, new_role = "ID") %>% #set identifier as id
  step_zv(all_predictors()) #remove columns from data when training data set have a single value (potentially the case for more rare offenses)
summary(number_charges_recipe)

#logistic regression model
logistic_mod <- 
  logistic_reg() %>% 
  set_engine("glm")

#create workflow
number_charges_wflow <- 
  workflow() %>% 
  add_model(logistic_mod) %>% 
  add_recipe(number_charges_recipe)

#fit model
number_charges_fit <- 
  number_charges_wflow %>% 
  fit(data = train_data)

#view fitted model
number_charges_fit %>% 
  pull_workflow_fit() %>% 
  tidy() 

#create prediction df 
number_charges_pred <- 
  predict(number_charges_fit, test_data, type = "prob") %>% 
  bind_cols(test_data)

#set threshold for prediction
threshold <- 0.214
number_charges_pred <- number_charges_pred %>% 
  mutate(prediction = as.factor(ifelse(.pred_1 > threshold, 1, 0))) %>% 
  dplyr::select(1:.pred_1, prediction, everything())


#roc curve
number_charges_pred %>% 
  roc_curve(truth = arrested_again_within_year, .pred_1) %>% 
  autoplot()

#area under curve
number_charges_pred %>% 
  roc_auc(truth = arrested_again_within_year, .pred_1)

#precision recall curve
number_charges_pred %>% 
  pr_curve(truth = arrested_again_within_year, .pred_1) %>% 
  autoplot()

#confusion matrix
cmat <- number_charges_pred %>%
  conf_mat(truth = "arrested_again_within_year", estimate = "prediction")
cmat
summary(cmat)


median(number_charges_pred$.pred_1, na.rm = TRUE)
```

```{r tables of summary stats for paper}
library(stargazer)

t1 <- pretrial_clean_1charge %>% 
  as.data.frame() %>% 
  dplyr::select(pretrial_detention_length, pretrial_age) %>% 
  stargazer(type = "text",
                summary.stat = c("min", "p25", "median", "p75", "max", "median", "sd"),
                out = "stargazer_table1.html")
```


