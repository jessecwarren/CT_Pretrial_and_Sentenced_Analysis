---
title: "CT_pretrial_and_sentenced_analysis"
author: "Jesse Warren"
date: "5/13/2020"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = FALSE)

library(janitor)
library(data.table)
library(RSocrata)
library(ggplot2)
library(ggrepel)
library(extrafont)
library(ggthemes)
library(reshape)
library(grid)
library(scales)
library(RColorBrewer)
library(gridExtra)
library(viridis)
library(hexbin)
library(sandwich)
library(stargazer)
library(lubridate)
library(stringdist)
library(scales)
library(cluster)    
library(factoextra)
library(fuzzyjoin)
library(MASS)
library(arm)



options(scipen=999)
library(tidyverse)
#load functions from helper files
source("Helper_functions/Data_loading_and_cleaning_functions.R")
```



```{r load pretrial data}
#2 options to load data:
  #1. straight from online open data repository for most up to date data
  #2. from local files (downloaded 5/2/2020)

#option 1.
#load pretrial data from Connecticut open data site  
pretrial_data_URL <- "https://data.ct.gov/Public-Safety/Accused-Pre-Trial-Inmates-in-Correctional-Faciliti/b674-jy6w"
#CT__analysis_pretrial_raw <- read.socrata((CT_pretrial_data_URL))

#option 2.
#load from local file, in Data/ folder
pretrial_raw <- fread("Data/Accused_Pre-Trial_Inmates_in_Correctional_Facilities.csv")

#fix race names using helper function
pretrial_raw <- fix_race_names_function(pretrial_raw)

#clean names, set variable types, fix dates using helper function
pretrial_raw <- pretrial_names_variable_types_dates_cleaning_function(pretrial_raw)

#create clean df to work with from here on out
pretrial_clean <- pretrial_raw

#remove inconsistently coded race and gender observations
pretrial_clean <- remove_inconsistently_coded_people_function(pretrial_clean)
```

```{r load sentenced data}
#2 options to load data:
  #1. straight from online open data repository for most up to date data
  #2. from local files (downloaded 5/7/2020)

#option 1.
#load pretrial data from Connecticut open data site  
sentenced_data_URL <- "https://data.ct.gov/Public-Safety/Sentenced-Inmates-in-Correctional-Facilities/um73-fxm4"
#sentenced_raw <- read.socrata((CT_sentenced_data_URL))

#option 2.
#load from local file, in Data/ folder
sentenced_raw <- fread("Data/Sentenced_Inmates_in_Correctional_Facilities.csv")

#fix race names
sentenced_raw <- fix_race_names_function(sentenced_raw)

#clean names, set variable types, fix dates
sentenced_raw <- sentenced_names_variable_types_dates_cleaning_function(sentenced_raw)

#create clean df to work with from here on out
sentenced_clean <- sentenced_raw

#remove inconsistently coded race and gender observations
sentenced_clean <- remove_inconsistently_coded_people_function(sentenced_clean)
```

```{r create smaller dataframes to work with to test and DELETE LATER}
##DELETE LATER##

#only get first x rows of each
#pretrial_clean <- head(pretrial_raw, 220000)
#sentenced_clean <- head(sentenced_raw, 220000)

pretrial_clean <- pretrial_raw
sentenced_clean <- sentenced_raw

```

```{r get one observation per charge for the pretrial detention dataset}
#Create new df that will have only one observation per charge
pretrial_clean_1charge <- pretrial_clean

#remove excess whitespace in offense variable
pretrial_clean_1charge <- pretrial_clean_1charge %>% 
  mutate(offense = str_squish(offense))

#Make a new variable for length of time in jail for person-admission
pretrial_clean_1charge <- pretrial_clean_1charge %>% 
   group_by(identifier, pretrial_latest_admission_date) %>%
   mutate(pretrial_detention_length = n())

#Generate indicators for date being 1)most recent download date, 2)earliest possible download date
most_recent_pretrial_download_date_in_dataset <- max(pretrial_clean_1charge$pretrial_download_date)
earliest_pretrial_download_date_in_dataset <- min(pretrial_clean_1charge$pretrial_download_date)

#this checks and sees if their pretrial download date is the most recent one available, indicating they are still in jail. max.still_in_jail tells is 1 if they are still in jail as of this data download
pretrial_clean_1charge$still_in_jail <- as.numeric(pretrial_clean_1charge$pretrial_download_date == most_recent_pretrial_download_date_in_dataset)
pretrial_clean_1charge <- pretrial_clean_1charge %>% 
   group_by(identifier, pretrial_latest_admission_date) %>%
   mutate(still_in_jail = max(still_in_jail),
          earliest_pretrial_download_date = min(pretrial_download_date))

#now just get one observation per charge. note that this takes the bond amount on the last day the person was in pretrial detention as their bond amount - for some observations this changes throughout the dataset. however the most recent observation is likely the most accurate one.
pretrial_clean_1charge <- pretrial_clean_1charge %>% 
  arrange(desc(pretrial_download_date)) %>% 
  group_by(identifier, pretrial_latest_admission_date, offense) %>% 
  slice(1) %>% 
  dplyr::rename(latest_pretrial_download_date = pretrial_download_date)

#add column with number of times each identifier is in dataset. note that some people have multiple observations because they were either:
  #arrested for multiple offenses at the same time
  #arrested different times for different offenses
pretrial_clean_1charge <- pretrial_clean_1charge %>% 
  group_by(identifier) %>% 
  mutate(number_pretrial_detention_charges = n())

#exclude people who exit the dataset in the first 60 days of recorded data (what should be the max time in pretrial detention). we dont observe their entire time in dataset at beginning, as they might have been in pretrial detention before data started being collected
pretrial_clean_1charge <- pretrial_clean_1charge %>% 
  filter(latest_pretrial_download_date > (60 + earliest_pretrial_download_date_in_dataset))

#rename offense category
pretrial_clean_1charge <- pretrial_clean_1charge %>% 
  dplyr::rename(pretrial_offense = offense)

```

```{r get one observation per charge for the sentencing dataset}
#Create new df that will have only one observation per charge
sentenced_clean_1charge <- sentenced_clean

#add indicator if person has life sentence (which is noted as a sentence length of 368897 in the dataset). for people with life sentences put 2100-01-01 for all end_sentence_dates 
sentenced_clean_1charge <- sentenced_clean_1charge %>% 
  mutate(life_sentence = case_when(sentence_days >= 368897 ~ 1,
                                   TRUE ~ 0)) %>% 
  mutate(end_sentence_date = case_when(sentence_days >= 368897 ~ ymd("2100-01-01"),
                                       TRUE ~ end_sentence_date))

#remove excess whitespace in offense variable
sentenced_clean_1charge <- sentenced_clean_1charge %>% 
  mutate(offense = str_squish(offense))

#check how close pretrial and offense variables line up, how many are in both datasets
sentenced_offense <- sentenced_clean_1charge$offense %>%
  unique() %>%
  as.data.frame() %>%
  dplyr::rename(offense = ".")
pretrial_offense <- pretrial_clean_1charge$offense %>%
  unique() %>%
  as.data.frame() %>%
  dplyr::rename(offense = ".")

#get number of offenses that only appear in one df, but not the other. most appear to be fairly rare crimes, and in general the offenses match up well
anti_join(pretrial_offense, sentenced_offense, by = "offense") %>%
  nrow()


#add earliest date each individual persons charge appears in the dataset
sentenced_clean_1charge <- sentenced_clean_1charge %>% 
  group_by(identifier, sentenced_latest_admission_date, offense) %>%
  mutate(earliest_sentenced_download_date = min(sentenced_download_date))

#people appear in the dataset each time the data is downloaded. this code keeps only the most recent download date for each individual charge (so people can appear multiple times if they have multiple different offenses admitted on different days)
sentenced_clean_1charge <- sentenced_clean_1charge %>% 
  arrange(desc(sentenced_download_date)) %>% 
  group_by(identifier, sentenced_latest_admission_date, offense) %>% 
  slice(1) %>% 
  dplyr::rename(latest_sentenced_download_date = sentenced_download_date)
  
#add column with number of times each identifier is in dataset.
sentenced_clean_1charge <- sentenced_clean_1charge %>% 
  group_by(identifier) %>% 
  mutate(number_convictions = n())

#add indicator if still in prison
most_recent_sentenced_download_date_in_dataset <- max(sentenced_clean_1charge$latest_sentenced_download_date)
sentenced_clean_1charge$still_in_prison <- as.numeric(sentenced_clean_1charge$latest_sentenced_download_date == most_recent_sentenced_download_date_in_dataset)

#rename offense category
sentenced_clean_1charge <- sentenced_clean_1charge %>% 
  dplyr::rename(sentenced_offense = offense)















#test out cleaning up observations were someone has the same admit date for multiple different charges - example: identifier "ZZHHCCHS" - DELETE LATER
sentenced_clean_1charge %>% 
  group_by(identifier, sentenced_latest_admission_date) %>% 
  filter(n() > 1) %>%
  view()
  
 
test <- sentenced_clean_1charge %>% 
  group_by(identifier, sentenced_latest_admission_date) %>% 
  mutate(id = 1:n()) %>% 
  mutate(offense2 = case_when(id == 2 ~ offense),
         offense3 = case_when(id == 3 ~ offense),
         offense4 = case_when(id == 4 ~ offense)) %>%
  mutate(sentence_days2 = case_when(id == 2 ~ sentence_days),
         sentence_days3 = case_when(id == 3 ~ sentence_days),
         sentence_days4 = case_when(id == 4 ~ sentence_days)) 


test <- sentenced_clean_1charge %>% 
  dplyr::select(identifier, sentence_days, sentenced_latest_admission_date, offense) %>% 
  group_by(identifier, sentenced_latest_admission_date) %>% 
  mutate(id = 1:n()) %>% 
  spread(id, offense)


test2 <- left_join(sentenced_clean_1charge, test, by = c("identifier", "sentenced_latest_admission_date"))







```



```{r merge dfs}
#merging these two datasets is difficult for a number of reasons. The two options for joining are to join based on offense, or based on latest_admission date. Issues are noted below:
 #1. Joining on offense: peoples offense may change from what it is recorded as during pretrial to what they are actually sentenced with, as they may take a plea bargain or the prosecutor may change the sentence before trial.
 #2. Joining on latest_admission_date : we can try to join based on the "latest_admission_date" field found in each df, but its unclear how well this field corresponds to each individual arrest, and whether it is updated each time someone enteres the dataset a second time for a new offense. Thus, joining on this means that people may be joined on a different charge than the one they actually were arrested/sentenced for.

#We can use two measures to determine how well the joins went:
  #1. The string distance between the pretrial and sentenced offense. Most joins should have a string distance of 0, but for those that don't, the string distance in many cases should be fairly small (ie the difference between "ASSAULT, FIRST DEGREE DF" and "ASSAULT, SECOND DEGREE DF")
 #2. The length of time between the last date they showed up in the pretrial dataset, and the earliest time they appear in the sentenced download date. For most people, this length of time shouldnt be too long, as most people take plea deals and thus the pretrial -> sentencing process is fairly quick.


#merge dfs using all observations
#merged <- full_join(pretrial_clean_1charge, sentenced_clean_1charge, by = c("identifier", "pretrial_latest_admission_date" = "sentenced_latest_admission_date"))

# #merge dfs using only observations in last year
# merged <- pretrial_clean_1charge %>%
#   filter(latest_pretrial_download_date > most_recent_pretrial_download_date_in_dataset - 365) %>%
#   left_join(sentenced_clean_1charge %>%
#     filter(latest_sentenced_download_date > most_recent_sentenced_download_date_in_dataset - 365),
#     by = c("identifier", "pretrial_latest_admission_date" = "sentenced_latest_admission_date"))

#merge dfs using only observations in last year but dont use admission date
merged <- pretrial_clean_1charge %>%
  filter(latest_pretrial_download_date > most_recent_pretrial_download_date_in_dataset - 365) %>%
  left_join(sentenced_clean_1charge %>%
    filter(latest_sentenced_download_date > most_recent_sentenced_download_date_in_dataset - 365),
    by = "identifier")

#view number of observations before and after merge
nrow(pretrial_clean_1charge)
nrow(sentenced_clean_1charge)
nrow(merged)

#Create columns to compare dates, compute string distance between offenses
merged <- merged %>% 
  mutate(pretrial_to_sentence_difference = earliest_sentenced_download_date - latest_pretrial_download_date) %>% 
  mutate(offense_string_dist = stringdist(pretrial_offense, sentenced_offense))

#visualize how well joins went
merged %>% 
  filter(!is.na(sentenced_offense)) %>% 
  ggplot(aes(x = offense_string_dist, y = pretrial_to_sentence_difference)) +
    #geom_point(size = .1) 
    stat_binhex() + scale_fill_viridis(name="n in hex")


merged %>% 
  filter(!is.na(sentenced_offense)) %>% 
  ggplot(aes(x = offense_string_dist)) +
  geom_histogram()

merged %>% 
  filter(!is.na(sentenced_offense)) %>% 
  ggplot(aes(x = pretrial_to_sentence_difference)) +
    geom_histogram()

```

```{r prepare merged data for analysis}
#create new clean df
merged_cleaned <- merged

#filter out people with negative pretrial_to_sentence_difference, which is likely due to an error in joins as people cant be in pretrial detention for a charge after theyve been sentenced for it
merged_cleaned <- merged_cleaned %>% 
  filter(pretrial_to_sentence_difference >= 0 | is.na(pretrial_to_sentence_difference))

#filter out longer string distances, which is also likely an error in joins. most offenses start to vary significantly after a string distance of 8
merged_cleaned <- merged_cleaned %>% 
  filter(offense_string_dist <= 9 | is.na(offense_string_dist))

#create 0/1 indicator of whether someone in the pretrial detention data appears in the sentenced data for that offense
merged_cleaned <- merged_cleaned %>% 
  mutate(sentenced = ifelse(!is.na(sentenced_offense), 1, 0))

#replace people who werent sentenced, who have NA sentenced_days with 0's
merged_cleaned <- merged_cleaned %>% 
  mutate(sentence_days = replace(sentence_days, is.na(sentence_days), 0))

#give 0s to people with nas for life sentence
merged_cleaned <- merged_cleaned %>% 
  mutate(life_sentence = replace(life_sentence, is.na(life_sentence), 0))

#replace NAs with 0s in still_in_prison and number_convictions columns
merged_cleaned <- merged_cleaned %>% 
  mutate(still_in_prison = replace(still_in_prison, is.na(still_in_prison), 0)) %>% 
  mutate(number_convictions = replace(number_convictions, is.na(number_convictions), 0))

#put 0's for still_in_jail column in case people have gone to prison in between downloading pretrial dataset and sentenced dataset, as download dates differ slightly
merged_cleaned <- merged_cleaned %>% 
    mutate(still_in_jail = replace(still_in_jail, still_in_jail == 1 & still_in_prison == 1, 0))

#remove unnecessary columns and ungroup
merged_cleaned <- merged_cleaned %>% 
  ungroup() %>% 
  dplyr::select(-sentenced_facility, -pretrial_facility, -race.y, -gender.y, -special_parole_end_date) %>% 
  dplyr::rename(race = race.x, gender = gender.x)

#visualize how well cleaning of joins went
merged_cleaned %>% 
  filter(!is.na(sentenced_offense)) %>% 
  ggplot(aes(x = offense_string_dist, y = pretrial_to_sentence_difference)) +
    geom_point(size = .1)


merged_cleaned %>% 
  filter(!is.na(sentenced_offense)) %>% 
  ggplot(aes(x = offense_string_dist)) +
  geom_histogram()

merged_cleaned %>% 
  filter(!is.na(sentenced_offense)) %>% 
  ggplot(aes(x = pretrial_to_sentence_difference)) +
    geom_histogram()

#compare how many people are lost in cleaning process
observations_in_merged <- merged %>% 
  filter(!is.na(sentenced_offense)) %>% 
  filter(!is.na(pretrial_detention_length)) %>% 
  nrow() 
observations_in_merged_cleaned <- merged_cleaned %>% 
  filter(!is.na(sentenced_offense)) %>% 
  filter(!is.na(pretrial_detention_length)) %>% 
  nrow()
#people removed by cleaning
observations_in_merged - observations_in_merged_cleaned
#percent of people removed
print("% people removed in cleaning process:")
100 - ((observations_in_merged_cleaned / observations_in_merged) * 100)

#see how many people were sentenced in the last year but werent found in the dataset, the best measure of how well the matching went. theoretically most should have been matched (we might expect some to not be matched if the people were in pretrial detention 1.5 years ago, then were sentenced in the last year but werent in pretrial detention in the past year)
sentenced_dataset_last_year_vec <- sentenced_clean_1charge %>%
  filter(earliest_sentenced_download_date > most_recent_sentenced_download_date_in_dataset - 365) %>% 
  dplyr::select(identifier) %>% 
  unique() %>% 
  pull()

print("% people who were sentenced in the last year that had a match in the final merged dataset. if perfect, this number should be close to 100%")
merged_cleaned %>% 
  filter(identifier %in% sentenced_dataset_last_year_vec) %>% 
  nrow() / 
  length(sentenced_dataset_last_year_vec) * 100



```

```{r visualize merged and cleaned dataset}

#look at relationship between pretrial detention length and sentence days
merged_cleaned %>%  
  filter(sentence_days < 5000) %>% 
  ggplot(aes(x = sentence_days, y = pretrial_detention_length, color = sentenced)) +
    geom_point()

```


```{r regression analysis}
#make pretrial offense a factor for regressions
merged_cleaned <- merged_cleaned %>%
  mutate(pretrial_offense = as.factor(pretrial_offense))

#set white and male as reference categories
merged_cleaned <- merged_cleaned %>%
  mutate(race = relevel(race, ref = 5),
         gender = relevel(gender, ref = 2))

#run regressions with sentence days as dependent variable
sink("Regression_results/sentence_days_regressions.txt")
lm_sentence_days <- merged_cleaned %>% 
  lm(sentence_days ~ bond_amount +
                 pretrial_detention_length +
                 race +
                 pretrial_age +
                 gender +
                 pretrial_offense,
     data = .)
print("OLS sentence days")
summary(lm_sentence_days)

logit_sentenced <- merged_cleaned %>%
  lm(sentenced ~ bond_amount +
                 pretrial_detention_length +
                 race +
                 pretrial_age +
                 gender +
                 pretrial_offense,
     family = "binomial",
     data = .)
print("Logit sentenced")
summary(logit_sentenced)

probit_sentenced <- merged_cleaned %>%
  lm(sentenced ~ bond_amount +
                 pretrial_detention_length +
                 race +
                 pretrial_age +
                 gender +
                 pretrial_offense,
     family = binomial(link = "probit"),
     data = .)
print("Probit sentenced")
summary(probit_sentenced)


bayes_glm_sentence_days <- merged_cleaned %>%
  bayesglm(sentence_days ~ bond_amount +
                 pretrial_detention_length +
                 race +
                 pretrial_age +
                 gender +
                 pretrial_offense,
     data = ., 
     family = poisson)
print("Bayes GLM")
summary(bayes_glm_sentence_days)
sink()

#OLS table
stargazer(lm_sentence_days,
          type = "html",
          title = "OLS regression results",
          dep.var.labels = "Sentenced length (days)",
          column.labels = "OLS",
          covariate.labels = c("Bond amount",
                               "Pretrial detention length (days)",
                               "Race - Asian", 
                               "Race - Black",
                               "Race - Hispanic",
                               "Race - Native American",
                               "Pretrial age (years)",
                               "Gender - Female"),
          digits = 2,
          single.row = TRUE,
          omit = "pretrial_offense",
          omit.stat = c("LL", "ser"),
          notes = "Pretrial offense category not included here as there are a large number of offense rows.",
          out = "Regression_results/sentence_days_OLS_table.html")

#logit and probit tables
stargazer(logit_sentenced,
          probit_sentenced,
          type = "html",
          align = TRUE,
          title = "Logit and probit regression results",
          dep.var.labels = "Sentenced (binary)",
          column.labels = c("Logit", "Probit"),
          covariate.labels = c("Bond amount",
                               "Pretrial detention length (days)",
                               "Race - Asian", 
                               "Race - Black",
                               "Race - Hispanic",
                               "Race - Native American",
                               "Pretrial age (years)",
                               "Gender - Female"),
          digits = 2,
          single.row = TRUE,
          omit = "pretrial_offense",
          omit.stat = c("LL", "ser"),
          notes = "Pretrial offense category not included here as there are a large number of offense rows.",
          out = "Regression_results/sentenced_logit_probit_table.html")

#all tables combined
stargazer(lm_sentence_days,
          logit_sentenced,
          probit_sentenced,
          type = "html",
          align = TRUE,
          title = "Regression results",
          dep.var.labels = c("Sentence length (days)", "Sentenced (binary)"),
          column.labels = c("OLS", "Logit", "Probit"),
          covariate.labels = c("Bond amount",
                               "Pretrial detention length (days)",
                               "Race - Asian", 
                               "Race - Black",
                               "Race - Hispanic",
                               "Race - Native American",
                               "Pretrial age (years)",
                               "Gender - Female"),
          digits = 2,
          single.row = TRUE,
          model.numbers = FALSE,
          omit = "pretrial_offense",
          omit.stat = c("LL", "ser"),
          notes = "Pretrial offense category not included here as there are a large number of offense rows.",
          out = "Regression_results/all_regression_tables_combined.html")
```


```{r Dafeng example cluster analysis}
#Dafeng sample code to use as example - DELETE THIS WHOLE CHUNK LATER
library(rworldmap)
labour <- readxl::read_xlsx("C:/Users/Jesses_PC/Documents/DataScience/Misc/Misc_datasets/labour.xlsx")

world = getMap(resolution = "low")
plot(world, xlim = c(-180, 180), ylim = c(-90, 90), asp = 1)
points(labour$longitude, labour$latitude, col = "red", cex = .6)
points(labour$longitude, labour$latitude, col = "red", cex = 1)


long = labour$longitude
lat = labour$latitude
coordinate = cbind(long, lat)
city = labour$city
rownames(coordinate) = labour$city

k5 = kmeans(coordinate, centers = 5)
k5

fviz_cluster(k5, data = coordinate)


crime <- readxl::read_xlsx("C:/Users/Jesses_PC/Documents/DataScience/Misc/Misc_datasets/crime.xlsx")

crime_cluster = crime
crime_cluster$State = NULL
rownames(crime_cluster) = crime$State

k3 = kmeans(crime_cluster, centers = 3)
fviz_cluster(k3, data = crime_cluster)

k2 = kmeans(crime_cluster, centers = 2)
fviz_cluster(k2, data = crime_cluster)

crime_summary2 = cbind(crime_cluster, k2$cluster)
crime_summary2


crime_cluster_copy = crime_cluster
crime_cluster_copy$Assault = crime_cluster_copy$Assault/100
crime_cluster_copy$UrbanPopulation = crime_cluster_copy$UrbanPopulation/100

k2_copy = kmeans(crime_cluster_copy, centers = 2)
fviz_cluster(k2_copy, data = crime_cluster_copy)

k3_copy = kmeans(crime_cluster_copy, centers = 3)
fviz_cluster(k3_copy, data = crime_cluster_copy)


fviz_nbclust(crime_cluster, kmeans, method = "silhouette")
fviz_nbclust(coordinate, kmeans, method = "silhouette")
k3 = kmeans(coordinate, centers = 3)
fviz_cluster(k3, data = coordinate)
```

```{r cluster analysis}
#create unique identifier variables for each charge
# merged_cleaned_cluster$identifier <- NULL
# rownames(merged_cleaned_cluster) <- merged_cleaned$identifier

#conduct cluster analysis, excluding those with life sentences
merged_cleaned_cluster <- merged_cleaned %>% 
  ungroup() %>% 
  filter(life_sentence == 0) %>% 
  dplyr::select(sentence_days, pretrial_detention_length)

k1 <- kmeans(merged_cleaned_cluster, centers = 3)

fviz_cluster(k1, data = merged_cleaned_cluster)
fviz_nbclust(head(merged_cleaned_cluster, 10000), kmeans, method = "silhouette")

```




