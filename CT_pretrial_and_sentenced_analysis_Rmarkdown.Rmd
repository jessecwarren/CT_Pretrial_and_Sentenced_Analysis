---
title: "Untitled"
author: "Jesse Warren"
date: "5/13/2020"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = FALSE)
library(tidyverse)
library(janitor)
library(data.table)
library(RSocrata)
library(ggplot2)
library(ggrepel)
library(extrafont)
library(ggthemes)
library(reshape)
library(grid)
library(scales)
library(RColorBrewer)
library(gridExtra)
library(viridis)
library(hexbin)
library(sandwich)
library(stargazer)
library(lubridate)
library(stringdist)
library(scales)
library(cluster)    
library(factoextra)



options(scipen=999)
```




```{r load pretrial data}
#2 options to load data:
  #1. straight from online open data repository for most up to date data
  #2. from local files (downloaded 5/2/2020)

#option 1.
#load pretrial data from Connecticut open data site  
pretrial_data_URL <- "https://data.ct.gov/Public-Safety/Accused-Pre-Trial-Inmates-in-Correctional-Faciliti/b674-jy6w"
#CT__analysis_pretrial_raw <- read.socrata((CT_pretrial_data_URL))

#option 2.
#load from local file, in Data/ folder
pretrial_raw <- fread("Data/Accused_Pre-Trial_Inmates_in_Correctional_Facilities.csv")

#create fix race names function
fix_race_names_function <- function(df) {
  df$RACE[df$RACE == 'AMER IND'] <- 'Native American'
  df$RACE[df$RACE == 'ASIAN'] <- 'Asian'
  df$RACE[df$RACE == 'BLACK'] <- 'Black'
  df$RACE[df$RACE == 'WHITE'] <- 'White'
  df$RACE[df$RACE == 'HISPANIC'] <- 'Hispanic'
  return(df)
}

#fix race names
pretrial_raw <- fix_race_names_function(pretrial_raw)

#clean names, set variable types, fix dates
pretrial_raw <- pretrial_raw %>% 
  clean_names() %>% 
  mutate(identifier = as.character(identifier),
         race = as.factor(race),
         gender = as.factor(gender),
         age = as.numeric(age),
         offense = as.character(offense),
         facility = as.factor(facility),
         detainer = as.factor(detainer),
         download_date = as.Date(download_date, '%m/%d/%Y'),
         latest_admission_date = as.Date(latest_admission_date, '%m/%d/%Y')) %>% 
  dplyr::rename(pretrial_age = age,
         pretrial_facility = facility,
         pretrial_detainer =  detainer,
         pretrial_download_date = download_date, 
         pretrial_latest_admission_date = latest_admission_date)

pretrial_clean <- pretrial_raw
```

```{r load sentenced data}
#2 options to load data:
  #1. straight from online open data repository for most up to date data
  #2. from local files (downloaded 5/7/2020)

#option 1.
#load pretrial data from Connecticut open data site  
sentenced_data_URL <- "https://data.ct.gov/Public-Safety/Sentenced-Inmates-in-Correctional-Facilities/um73-fxm4"
#sentenced_raw <- read.socrata((CT_sentenced_data_URL))

#option 2.
#load from local file, in Data/ folder
sentenced_raw <- fread("Data/Sentenced_Inmates_in_Correctional_Facilities.csv")

#fix race names
sentenced_raw <- fix_race_names_function(sentenced_raw)

#clean names, set variable types, fix dates
sentenced_raw <- sentenced_raw %>% 
  clean_names() %>% 
  mutate(identifier = as.character(identifier),
         race = as.factor(race),
         gender = as.factor(gender),
         age = as.numeric(age),
         offense = as.character(offense),
         facility = as.factor(facility),
         detainer = as.factor(detainer),
         download_date = as.Date(download_date, '%m/%d/%Y'),
         end_sentence_date = as.Date(end_sentence_date, '%m/%d/%Y'),
         latest_admission_date = as.Date(latest_admission_date, '%m/%d/%Y'),
         special_parole_end_date = as.Date(special_parole_end_date, '%m/%d/%Y')) %>% 
  dplyr::rename(sentenced_age = age, 
         sentenced_facility = facility, 
         sentenced_detainer = detainer,
         sentenced_download_date = download_date,
         sentenced_latest_admission_date = latest_admission_date)

sentenced_clean <- sentenced_raw
```

```{r create smaller dataframes to work with to test and DELETE LATER}
##DELETE LATER##

#only get first x rows of each
#pretrial_clean <- head(pretrial_raw, 220000)
#sentenced_clean <- head(sentenced_raw, 220000)

pretrial_clean <- pretrial_raw
sentenced_clean <- sentenced_raw

```

```{r remove inconsistently coded race and gender observations}
#create dfs of unique people
pretrial_people <- unique(pretrial_clean[,c("identifier", "race", "gender")])
sentenced_people <- unique(sentenced_clean[,c("identifier", "race", "gender")])

#get difference between number of unique people, and number of unique people by race and gender as well to see if some people are being coded multiple times as different races/genders
nrow(pretrial_people) - length(unique(pretrial_clean[,"identifier"])) 
nrow(sentenced_people) - length(unique(sentenced_clean[,"identifier"])) 


#exclude the people coded with different race and/or genders from both pretrial and sentenced dfs
exclude_inconsistent_people_vec <- pretrial_people$identifier[duplicated(pretrial_people$identifier)]
exclude_inconsistent_people_vec <- append(exclude_inconsistent_people_vec, sentenced_people$identifier[duplicated(sentenced_people$identifier)])

pretrial_clean <- pretrial_clean %>% 
  filter(!identifier %in% exclude_inconsistent_people_vec)
sentenced_clean <- sentenced_clean %>% 
  filter(!identifier %in% exclude_inconsistent_people_vec)
```

```{r get one observation per charge for the pretrial detention dataset}
#Create new df that will have only one observation per charge
pretrial_clean_1charge <- pretrial_clean

#remove excess whitespace in offense variable
pretrial_clean_1charge <- pretrial_clean_1charge %>% 
  mutate(offense = str_squish(offense))

#Make a new variable for length of time in jail for person-admission
pretrial_clean_1charge <- pretrial_clean_1charge %>% 
   group_by(identifier, pretrial_latest_admission_date) %>%
   mutate(pretrial_detention_length = n())

#Generate indicators for date being 1)most recent download date, 2)earliest possible download date
most_recent_pretrial_download_date_in_dataset <- max(pretrial_clean_1charge$pretrial_download_date)
earliest_pretrial_download_date_in_dataset <- min(pretrial_clean_1charge$pretrial_download_date)

#this checks and sees if their pretrial download date is the most recent one available, indicating they are still in jail. max.still_in_jail tells is 1 if they are still in jail as of this data download
pretrial_clean_1charge$still_in_jail <- as.numeric(pretrial_clean_1charge$pretrial_download_date == most_recent_pretrial_download_date_in_dataset)
pretrial_clean_1charge <- pretrial_clean_1charge %>% 
   group_by(identifier, pretrial_latest_admission_date) %>%
   mutate(still_in_jail = max(still_in_jail),
          earliest_pretrial_download_date = min(pretrial_download_date))

#now just get one observation per charge. note that this takes the bond amount on the last day the person was in pretrial detention as their bond amount - for some observations this changes throughout the dataset. however the most recent observation is likely the most accurate one.
pretrial_clean_1charge <- pretrial_clean_1charge %>% 
  arrange(desc(pretrial_download_date)) %>% 
  group_by(identifier, pretrial_latest_admission_date, offense) %>% 
  slice(1) %>% 
  dplyr::rename(latest_pretrial_download_date = pretrial_download_date)

#add column with number of times each identifier is in dataset. note that some people have multiple observations because they were either:
  #arrested for multiple offenses at the same time
  #arrested different times for different offenses
pretrial_clean_1charge <- pretrial_clean_1charge %>% 
  group_by(identifier) %>% 
  mutate(number_pretrial_detention_charges = n())

#exclude people who exit the dataset in the first 60 days of recorded data (what should be the max time in pretrial detention). we dont observe their entire time in dataset at beginning, as they might have been in pretrial detention before data started being collected
pretrial_clean_1charge <- pretrial_clean_1charge %>% 
  filter(latest_pretrial_download_date > (60 + earliest_pretrial_download_date_in_dataset))

```

```{r get one observation per charge for the sentencing dataset}
#Create new df that will have only one observation per charge
sentenced_clean_1charge <- sentenced_clean

#add indicator if person has life sentence (which is noted as a sentence length of 368897 in the dataset). for people with life sentences put 2100-01-01 for all end_sentence_dates 
sentenced_clean_1charge <- sentenced_clean_1charge %>% 
  mutate(life_sentence = case_when(sentence_days >= 368897 ~ 1,
                                   TRUE ~ 0)) %>% 
  mutate(end_sentence_date = case_when(sentence_days >= 368897 ~ ymd("2100-01-01"),
                                       TRUE ~ end_sentence_date))

#remove excess whitespace in offense variable
sentenced_clean_1charge <- sentenced_clean_1charge %>% 
  mutate(offense = str_squish(offense))

#check how close pretrial and offense variables line up, how many are in both datasets
sentenced_offense <- sentenced_clean_1charge$offense %>%
  unique() %>%
  as.data.frame() %>%
  dplyr::rename(offense = ".")
pretrial_offense <- pretrial_clean_1charge$offense %>%
  unique() %>%
  as.data.frame() %>%
  dplyr::rename(offense = ".")

#get number of offenses that only appear in one df, but not the other. most appear to be fairly rare crimes, and in general the offenses match up well
anti_join(pretrial_offense, sentenced_offense, by = "offense") %>%
  nrow()


#add earliest date each individual persons charge appears in the dataset
sentenced_clean_1charge <- sentenced_clean_1charge %>% 
  group_by(identifier, sentenced_latest_admission_date, offense) %>%
  mutate(earliest_sentenced_download_date = min(sentenced_download_date))

#people appear in the dataset each time the data is downloaded. this code keeps only the most recent download date for each individual charge (so people can appear multiple times if they have multiple different offenses admitted on different days)
sentenced_clean_1charge <- sentenced_clean_1charge %>% 
  arrange(desc(sentenced_download_date)) %>% 
  group_by(identifier, sentenced_latest_admission_date, offense) %>% 
  slice(1) %>% 
  dplyr::rename(latest_sentenced_download_date = sentenced_download_date)
  
#add column with number of times each identifier is in dataset.
sentenced_clean_1charge <- sentenced_clean_1charge %>% 
  group_by(identifier) %>% 
  mutate(number_convictions = n())

#add indicator if still in prison
most_recent_sentenced_download_date_in_dataset <- max(sentenced_clean_1charge$latest_sentenced_download_date)
sentenced_clean_1charge$still_in_prison <- as.numeric(sentenced_clean_1charge$latest_sentenced_download_date == most_recent_sentenced_download_date_in_dataset)
```



```{r merge dfs}
#merging these two datasets is difficult for a number of reasons. The two options for joining are to join based on offense, or based on latest_admission date. Issues are noted below:
 #1. Joining on offense: peoples offense may change from what it is recorded as during pretrial to what they are actually sentenced with, as they may take a plea bargain or the prosecutor may change the sentence before trial.
 #2. Joining on latest_admission_date : we can try to join based on the "latest_admission_date" field found in each df, but its unclear how well this field corresponds to each individual arrest, and whether it is updated each time someone enteres the dataset a second time for a new offense. Thus, joining on this means that people may be joined on a different charge than the one they actually were arrested/sentenced for.

#We can use two measures to determine how well the joins went:
  #1. The string distance between the pretrial and sentenced offense. Most joins should have a string distance of 0, but for those that don't, the string distance in many cases should be fairly small (ie the difference between "ASSAULT, FIRST DEGREE DF" and "ASSAULT, SECOND DEGREE DF")
 #2. The length of time between the last date they showed up in the pretrial dataset, and the earliest time they appear in the sentenced download date. For most people, this length of time shouldnt be too long, as most people take plea deals and thus the pretrial -> sentencing process is fairly quick.

#merge dfs
merged <- full_join(pretrial_clean_1charge, sentenced_clean_1charge, by = c("identifier", "pretrial_latest_admission_date" = "sentenced_latest_admission_date"))


nrow(pretrial_clean_1charge)
nrow(sentenced_clean_1charge)
nrow(merged)

#Create columns to compare dates, compute string distance between offenses
merged <- merged %>% 
  mutate(pretrial_to_sentence_difference = earliest_sentenced_download_date - latest_pretrial_download_date) %>% 
  mutate(string_dist = stringdist(offense.x, offense.y))

merged %>% 
  filter(!is.na(offense.y)) %>% 
  ggplot(aes(x = string_dist, y = pretrial_to_sentence_difference)) +
    geom_point(size = .1)

merged %>% 
  filter(!is.na(offense.y)) %>% 
  ggplot(aes(x = string_dist)) +
  geom_histogram()

merged %>% 
  filter(!is.na(offense.y)) %>% 
  ggplot(aes(x = pretrial_to_sentence_difference)) +
    geom_histogram()



```

```{r prepare merged data for analysis}
#clean up names
merged_cleaned <- merged %>% 
  dplyr::rename(pretrial_offense = offense.x,
                sentenced_offense = offense.y)

#filter out people with negative pretrial_to_sentence_difference, which is likely due to an error in joins
merged_cleaned <- merged_cleaned %>% 
  filter(pretrial_to_sentence_difference >= 0 | is.na(pretrial_to_sentence_difference))

#filter out longer string distances, which is also likely an error in joins
merged_cleaned <- merged_cleaned %>% 
  filter(string_dist <= 15 | is.na(string_dist))

#create 0/1 indicator of whether someone in the pretrial detention data appears in the sentenced data for that offense
merged_cleaned <- merged_cleaned %>% 
  mutate(sentenced = ifelse(!is.na(sentenced_offense), 1, 0))

#replace people who werent sentenced, who have NA sentenced_days with 0's
merged_cleaned <- merged_cleaned %>% 
  mutate(sentence_days = replace(sentence_days, is.na(sentence_days), 0))

#filter out people not in pretrial detention dataset
merged_cleaned <- merged_cleaned %>% 
  filter(!is.na(pretrial_detention_length))

#give 0s to people with nas for life sentence
merged_cleaned <- merged_cleaned %>% 
  mutate(life_sentence = replace(life_sentence, is.na(life_sentence), 0))
```

```{r visualize merged and cleaned dataset}

#look at relationship between pretrial detention length and sentence days
merged_cleaned %>% 
  filter(sentence_days < 5000) %>% 
  ggplot(aes(x = sentence_days, y = pretrial_detention_length)) +
    geom_point()



ggplot(data=bd, aes(x=bond_amount, y=dur))+
  stat_binhex() + scale_fill_viridis(name="n in hex") +
  theme_minimal() +
  theme(plot.title = element_text(hjust = 0)) +
  labs(x="Initial Bond Amount ($)", y="Jail Stay (Days)", caption="\nThe plot displays the frequency of bond amount/jail stay combinations with hexagonal bins. (See legend.) \nObservations include admissions which concluded in a release from jail before 5/2/2020. (n=58,882)")+
  scale_y_log10(labels=comma)+
  scale_x_log10(labels=comma)+ 
  ggtitle("Initial Bond and Jail Stay", subtitle = "Data Available via Connecticut Open Data")

test[1]
```



```{r Dafeng example cluster analysis}
#Dafeng sample code to use as example - DELETE THIS WHOLE CHUNK LATER
library(rworldmap)
labour <- readxl::read_xlsx("C:/Users/Jesses_PC/Documents/DataScience/Misc/Misc_datasets/labour.xlsx")

world = getMap(resolution = "low")
plot(world, xlim = c(-180, 180), ylim = c(-90, 90), asp = 1)
points(labour$longitude, labour$latitude, col = "red", cex = .6)
points(labour$longitude, labour$latitude, col = "red", cex = 1)


long = labour$longitude
lat = labour$latitude
coordinate = cbind(long, lat)
city = labour$city
rownames(coordinate) = labour$city

k5 = kmeans(coordinate, centers = 5)
k5

fviz_cluster(k5, data = coordinate)


crime <- readxl::read_xlsx("C:/Users/Jesses_PC/Documents/DataScience/Misc/Misc_datasets/crime.xlsx")

crime_cluster = crime
crime_cluster$State = NULL
rownames(crime_cluster) = crime$State

k3 = kmeans(crime_cluster, centers = 3)
fviz_cluster(k3, data = crime_cluster)

k2 = kmeans(crime_cluster, centers = 2)
fviz_cluster(k2, data = crime_cluster)

crime_summary2 = cbind(crime_cluster, k2$cluster)
crime_summary2


crime_cluster_copy = crime_cluster
crime_cluster_copy$Assault = crime_cluster_copy$Assault/100
crime_cluster_copy$UrbanPopulation = crime_cluster_copy$UrbanPopulation/100

k2_copy = kmeans(crime_cluster_copy, centers = 2)
fviz_cluster(k2_copy, data = crime_cluster_copy)

k3_copy = kmeans(crime_cluster_copy, centers = 3)
fviz_cluster(k3_copy, data = crime_cluster_copy)


fviz_nbclust(crime_cluster, kmeans, method = "silhouette")
fviz_nbclust(coordinate, kmeans, method = "silhouette")
k3 = kmeans(coordinate, centers = 3)
fviz_cluster(k3, data = coordinate)
```

```{r cluster analysis}
#create unique identifier variables for each charge
# merged_cleaned_cluster$identifier <- NULL
# rownames(merged_cleaned_cluster) <- merged_cleaned$identifier

#conduct cluster analysis, excluding those with life sentences
merged_cleaned_cluster <- merged_cleaned %>% 
  ungroup() %>% 
  filter(life_sentence == 0) %>% 
  select(sentence_days, pretrial_detention_length, bond_amount)

k1 <- kmeans(merged_cleaned_cluster, centers = 3)

fviz_cluster(k1, data = merged_cleaned_cluster)
fviz_nbclust(head(merged_cleaned_cluster, 10000), kmeans, method = "silhouette")

```

```{r OLS regression analysis}

#run regression with sentenced as dependent variable
lm1 <- merged_cleaned %>% 
  lm(sentenced ~ race.x +
                 as.factor(pretrial_offense) +
                 gender.x +
                 bond_amount +
                 pretrial_detention_length,
     data = .)

logit1 <- merged_cleaned %>% 
  glm(sentenced ~ race.x +
                 as.factor(pretrial_offense) +
                 gender.x +
                 bond_amount +
                 pretrial_detention_length,
     family = "binomial",
     data = .)

summary(lm1)
summary(logit1)
```

