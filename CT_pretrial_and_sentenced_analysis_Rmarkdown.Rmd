---
title: "Untitled"
author: "Jesse Warren"
date: "5/13/2020"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = FALSE)
library(tidyverse)
library(janitor)
library(data.table)
library(RSocrata)
library(ggplot2)
library(ggrepel)
library(extrafont)
library(ggthemes)
library(reshape)
library(grid)
library(scales)
library(RColorBrewer)
library(gridExtra)
library(viridis)
library(hexbin)
library(sandwich)
library(stargazer)
library(lubridate)
library(stringdist)
library(scales)
library(cluster)    
library(factoextra)



options(scipen=999)
```




```{r load pretrial data}
#2 options to load data:
  #1. straight from online open data repository for most up to date data
  #2. from local files (downloaded 5/2/2020)

#option 1.
#load pretrial data from Connecticut open data site  
CT_analysis_pretrial_data_URL <- "https://data.ct.gov/Public-Safety/Accused-Pre-Trial-Inmates-in-Correctional-Faciliti/b674-jy6w"
#CT__analysis_pretrial_raw <- read.socrata((CT_pretrial_data_URL))

#option 2.
#load from local file, in Data/ folder
CT_analysis_pretrial_raw <- fread("Data/Accused_Pre-Trial_Inmates_in_Correctional_Facilities.csv")

#create fix race names function
fix_race_names_function <- function(df) {
  df$RACE[df$RACE == 'AMER IND'] <- 'Native American'
  df$RACE[df$RACE == 'ASIAN'] <- 'Asian'
  df$RACE[df$RACE == 'BLACK'] <- 'Black'
  df$RACE[df$RACE == 'WHITE'] <- 'White'
  df$RACE[df$RACE == 'HISPANIC'] <- 'Hispanic'
  return(df)
}

#fix race names
CT_analysis_pretrial_raw <- fix_race_names_function(CT_analysis_pretrial_raw)

#clean names, set variable types, fix dates
CT_analysis_pretrial_raw <- CT_analysis_pretrial_raw %>% 
  clean_names() %>% 
  mutate(identifier = as.character(identifier),
         race = as.factor(race),
         gender = as.factor(gender),
         age = as.numeric(age),
         offense = as.character(offense),
         facility = as.factor(facility),
         detainer = as.factor(detainer),
         download_date = as.Date(download_date, '%m/%d/%Y'),
         latest_admission_date = as.Date(latest_admission_date, '%m/%d/%Y')) %>% 
  dplyr::rename(pretrial_age = age,
         pretrial_facility = facility,
         pretrial_detainer =  detainer,
         pretrial_download_date = download_date, 
         pretrial_latest_admission_date = latest_admission_date)

CT_analysis_pretrial_clean <- CT_analysis_pretrial_raw
```

```{r load sentenced data}
#2 options to load data:
  #1. straight from online open data repository for most up to date data
  #2. from local files (downloaded 5/7/2020)

#option 1.
#load pretrial data from Connecticut open data site  
CT_analysis_sentenced_data_URL <- "https://data.ct.gov/Public-Safety/Sentenced-Inmates-in-Correctional-Facilities/um73-fxm4"
#CT_analysis_sentenced_raw <- read.socrata((CT_sentenced_data_URL))

#option 2.
#load from local file, in Data/ folder
CT_analysis_sentenced_raw <- fread("Data/Sentenced_Inmates_in_Correctional_Facilities.csv")

#fix race names
CT_analysis_sentenced_raw <- fix_race_names_function(CT_analysis_sentenced_raw)

#clean names, set variable types, fix dates
CT_analysis_sentenced_raw <- CT_analysis_sentenced_raw %>% 
  clean_names() %>% 
  mutate(identifier = as.character(identifier),
         race = as.factor(race),
         gender = as.factor(gender),
         age = as.numeric(age),
         offense = as.character(offense),
         facility = as.factor(facility),
         detainer = as.factor(detainer),
         download_date = as.Date(download_date, '%m/%d/%Y'),
         end_sentence_date = as.Date(end_sentence_date, '%m/%d/%Y'),
         latest_admission_date = as.Date(latest_admission_date, '%m/%d/%Y'),
         special_parole_end_date = as.Date(special_parole_end_date, '%m/%d/%Y')) %>% 
  dplyr::rename(sentenced_age = age, 
         sentenced_facility = facility, 
         sentenced_detainer = detainer,
         sentenced_download_date = download_date,
         sentenced_latest_admission_date = latest_admission_date)

CT_analysis_sentenced_clean <- CT_analysis_sentenced_raw
```

```{r create smaller dataframes to work with to test and DELETE LATER}
##DELETE LATER##

#only get first x rows of each
# CT_analysis_pretrial_clean <- head(CT_analysis_pretrial_raw, 220000)
#CT_analysis_sentenced_clean <- head(CT_analysis_sentenced_raw, 220000)

CT_analysis_pretrial_clean <- CT_analysis_pretrial_raw
CT_analysis_sentenced_clean <- CT_analysis_sentenced_raw

```

```{r remove inconsistently coded race and gender observations}
#create dfs of unique people
CT_analysis_pretrial_people <- unique(CT_analysis_pretrial_clean[,c("identifier", "race", "gender")])
CT_analysis_sentenced_people <- unique(CT_analysis_sentenced_clean[,c("identifier", "race", "gender")])

#get difference between number of unique people, and number of unique people by race and gender as well to see if some people are being coded multiple times as different races/genders
nrow(CT_analysis_pretrial_people) - length(unique(CT_analysis_pretrial_clean[,"identifier"])) 
nrow(CT_analysis_sentenced_people) - length(unique(CT_analysis_sentenced_clean[,"identifier"])) 


#exclude the people coded with different race and/or genders
exclude_inconsistent_people_vec <- CT_analysis_pretrial_people$identifier[duplicated(CT_analysis_pretrial_people$identifier)]
exclude_inconsistent_people_vec <- append(exclude_inconsistent_people_vec, CT_analysis_sentenced_people$identifier[duplicated(CT_analysis_sentenced_people$identifier)])

CT_analysis_pretrial_clean <- CT_analysis_pretrial_clean %>% 
  filter(!identifier %in% exclude_inconsistent_people_vec)
CT_analysis_sentenced_clean <- CT_analysis_sentenced_clean %>% 
  filter(!identifier %in% exclude_inconsistent_people_vec)
```

```{r get one observation per charge for the pretrial detention dataset}
#Create new df that will have only one observation per charge
CT_analysis_pretrial_clean_1obs <- CT_analysis_pretrial_clean

#remove excess whitespace in offense variable
CT_analysis_pretrial_clean_1obs <- CT_analysis_pretrial_clean_1obs %>% 
  mutate(offense = str_squish(offense))

#Make a new variable for length of time in jail for person-admission
CT_analysis_pretrial_clean_1obs <- CT_analysis_pretrial_clean_1obs %>% 
   group_by(identifier, pretrial_latest_admission_date) %>%
   mutate(pretrial_detention_length = n())

#Generate indicators for date being 1)most recent download date, 2)earliest possible download date
most_recent_pretrial_download_date_in_dataset <- max(CT_analysis_pretrial_clean_1obs$pretrial_download_date)
earliest_pretrial_download_date_in_dataset <- min(CT_analysis_pretrial_clean_1obs$pretrial_download_date)

#this checks and sees if their pretrial download date is the most recent one available, indicating they are still in jail. max.still_in_jail tells is 1 if they are still in jail as of this data download
CT_analysis_pretrial_clean_1obs$still_in_jail <- as.numeric(CT_analysis_pretrial_clean_1obs$pretrial_download_date == most_recent_pretrial_download_date_in_dataset)
CT_analysis_pretrial_clean_1obs <- CT_analysis_pretrial_clean_1obs %>% 
   group_by(identifier, pretrial_latest_admission_date) %>%
   mutate(still_in_jail = max(still_in_jail),
          earliest_pretrial_download_date = min(pretrial_download_date))

#now just get one observation per charge. note that this takes the bond amount on the last day the person was in pretrial detention as their bond amount - for some observations this changes throughout the dataset. however the most recent observation is likely the most accurate one.
CT_analysis_pretrial_clean_1obs <- CT_analysis_pretrial_clean_1obs %>% 
  arrange(desc(pretrial_download_date)) %>% 
  group_by(identifier, pretrial_latest_admission_date, offense) %>% 
  slice(1) %>% 
  dplyr::rename(latest_pretrial_download_date = pretrial_download_date)

#add column with number of times each identifier is in dataset. note that some people have multiple observations because they were either:
  #arrested for multiple offenses at the same time
  #arrested different times for different offenses
CT_analysis_pretrial_clean_1obs <- CT_analysis_pretrial_clean_1obs %>% 
  group_by(identifier) %>% 
  mutate(number_pretrial_detention_charges = n())

#exclude people who exit the dataset in the first 60 days of recorded data (what should be the max time in pretrial detention). we dont observe their entire time in dataset at beginning, as they might have been in pretrial detention before data started being collected
test <- CT_analysis_pretrial_clean_1obs %>% 
  filter(latest_pretrial_download_date > (60 + earliest_pretrial_download_date_in_dataset))


nrow(CT_analysis_pretrial_clean_1obs)
nrow(test)
```

```{r get one observation per charge for the sentencing dataset}
#Create new df that will have only one observation per charge
CT_analysis_sentenced_clean_1obs <- CT_analysis_sentenced_clean

#add indicator if person has life sentence (which is noted as a sentence length of 368897 in the dataset). for people with life sentences put 2100-01-01 for all end_sentence_dates 
CT_analysis_sentenced_clean_1obs <- CT_analysis_sentenced_clean_1obs %>% 
  mutate(life_sentence = case_when(sentence_days <= 368897 ~ 1,
                                   TRUE ~ 0)) %>% 
  mutate(end_sentence_date = case_when(sentence_days == 368897 ~ ymd("2100-01-01"),
                                       TRUE ~ end_sentence_date))

#trim whitespace from offense names
CT_analysis_sentenced_clean_1obs <- CT_analysis_sentenced_clean_1obs %>% 
  mutate(offense = str_squish(offense))

#add earliest date each individual persons charge appears in the dataset
CT_analysis_sentenced_clean_1obs <- CT_analysis_sentenced_clean_1obs %>% 
  group_by(identifier, sentenced_latest_admission_date, offense) %>%
  mutate(earliest_sentenced_download_date = min(sentenced_download_date))

#people appear in the dataset each time the data is downloaded. this code keeps only the most recent download date for each individual charge (so people can appear multiple times if they have multiple different offenses admitted on different days)
CT_analysis_sentenced_clean_1obs <- CT_analysis_sentenced_clean_1obs %>% 
  arrange(desc(sentenced_download_date)) %>% 
  group_by(identifier, sentenced_latest_admission_date, offense) %>% 
  slice(1) %>% 
  dplyr::rename(latest_sentenced_download_date = sentenced_download_date)
  
#add column with number of times each identifier is in dataset.
CT_analysis_sentenced_clean_1obs <- CT_analysis_sentenced_clean_1obs %>% 
  group_by(identifier) %>% 
  mutate(number_convictions = n())

#filter out people with na's for end_sentence_date, which likely indicates errors in their sentence_days as well
CT_analysis_sentenced_clean_1obs <- CT_analysis_sentenced_clean_1obs %>% 
  filter(!is.na(end_sentence_date))

```



```{r merge dfs}
#merging these two datasets is difficult for a number of reasons. The two options for joining are to join based on offense, or based on latest_admission date. Issues are noted below:
 #1. Joining on offense: peoples offense may change from what it is recorded as during pretrial to what they are actually sentenced with, as they may take a plea bargain or the prosecutor may change the sentence before trial.
 #2. Joining on latest_admission_date : we can try to join based on the "latest_admission_date" field found in each df, but its unclear how well this field corresponds to each individual arrest, and whether it is updated each time someone enteres the dataset a second time for a new offense. Thus, joining on this means that people may be joined on a different charge than the one they actually were arrested/sentenced for.

#We can use two measures to determine how well the joins went:
  #1. The string distance between the pretrial and sentenced offense. Most joins should have a string distance of 0, but for those that don't, the string distance in many cases should be fairly small (ie the difference between "ASSAULT, FIRST DEGREE DF" and "ASSAULT, SECOND DEGREE DF")
 #2. The length of time between the last date they showed up in the pretrial dataset, and the earliest time they appear in the sentenced download date. For most people, this length of time shouldnt be too long, as most people take plea deals and thus the pretrial -> sentencing process is fairly quick.

#merge dfs
CT_analysis_merged <- full_join(CT_analysis_pretrial_clean_1obs, CT_analysis_sentenced_clean_1obs, by = c("identifier", "pretrial_latest_admission_date" = "sentenced_latest_admission_date"))


nrow(CT_analysis_pretrial_clean_1obs)
nrow(CT_analysis_sentenced_clean_1obs)
nrow(CT_analysis_merged)

#Create columns to compare dates, compute string distance between offenses
CT_analysis_merged <- CT_analysis_merged %>% 
  mutate(pretrial_to_sentence_difference = earliest_sentenced_download_date - latest_pretrial_download_date) %>% 
  mutate(string_dist = stringdist(offense.x, offense.y))

CT_analysis_merged %>% 
  filter(!is.na(offense.y)) %>% 
  ggplot(aes(x = string_dist, y = pretrial_to_sentence_difference)) +
    geom_point(size = .1)

CT_analysis_merged %>% 
  filter(!is.na(offense.y)) %>% 
  ggplot(aes(x = string_dist)) +
  geom_histogram()

CT_analysis_merged %>% 
  filter(!is.na(offense.y)) %>% 
  ggplot(aes(x = pretrial_to_sentence_difference)) +
    geom_histogram()



```

```{r prepare merged data for analysis}
#clean up names
CT_analysis_merged_cleaned <- CT_analysis_merged %>% 
  dplyr::rename(pretrial_offense = offense.x,
                sentenced_offense = offense.y)

#filter out people with negative pretrial_to_sentence_difference, which is likely due to an error in joins
CT_analysis_merged_cleaned <- CT_analysis_merged_cleaned %>% 
  filter(pretrial_to_sentence_difference >= 0 | is.na(pretrial_to_sentence_difference))

#filter out longer string distances, which is also likely an error in joins
CT_analysis_merged_cleaned <- CT_analysis_merged_cleaned %>% 
  filter(string_dist <= 15 | is.na(string_dist))

#create 0/1 indicator of whether someone in the pretrial detention data appears in the sentenced data for that offense
CT_analysis_merged_cleaned <- CT_analysis_merged_cleaned %>% 
  mutate(sentenced = ifelse(!is.na(sentenced_offense), 1, 0))

#replace people who werent sentenced, who have NA sentenced_days with 0's
CT_analysis_merged_cleaned <- CT_analysis_merged_cleaned %>% 
  mutate(sentence_days = replace(sentence_days, is.na(sentence_days), 0))

#filter out people not in pretrial detention dataset
CT_analysis_merged_cleaned <- CT_analysis_merged_cleaned %>% 
  filter(!is.na(pretrial_detention_length))

#give 0s to people with nas for life sentence
CT_analysis_merged_cleaned <- CT_analysis_merged_cleaned %>% 
  mutate(life_sentence = replace(life_sentence, is.na(life_sentence), 0))
```

```{r visualize merged and cleaned dataset}

CT_analysis_merged_cleaned %>% 
  ggplot(aes(x = sentence_days, y = pretrial_detention_length)) +
    geom_point()


test <- CT_analysis_merged_cleaned %>% 
  ungroup() %>% 
  select(sentence_days) %>% 
  arrange(-sentence_days)

test[1]
```



```{r Dafeng example cluster analysis}
#Dafeng sample code to use as example - DELETE THIS WHOLE CHUNK LATER
library(rworldmap)
labour <- readxl::read_xlsx("C:/Users/Jesses_PC/Documents/DataScience/Misc/Misc_datasets/labour.xlsx")

world = getMap(resolution = "low")
plot(world, xlim = c(-180, 180), ylim = c(-90, 90), asp = 1)
points(labour$longitude, labour$latitude, col = "red", cex = .6)
points(labour$longitude, labour$latitude, col = "red", cex = 1)


long = labour$longitude
lat = labour$latitude
coordinate = cbind(long, lat)
city = labour$city
rownames(coordinate) = labour$city

k5 = kmeans(coordinate, centers = 5)
k5

fviz_cluster(k5, data = coordinate)


crime <- readxl::read_xlsx("C:/Users/Jesses_PC/Documents/DataScience/Misc/Misc_datasets/crime.xlsx")

crime_cluster = crime
crime_cluster$State = NULL
rownames(crime_cluster) = crime$State

k3 = kmeans(crime_cluster, centers = 3)
fviz_cluster(k3, data = crime_cluster)

k2 = kmeans(crime_cluster, centers = 2)
fviz_cluster(k2, data = crime_cluster)

crime_summary2 = cbind(crime_cluster, k2$cluster)
crime_summary2


crime_cluster_copy = crime_cluster
crime_cluster_copy$Assault = crime_cluster_copy$Assault/100
crime_cluster_copy$UrbanPopulation = crime_cluster_copy$UrbanPopulation/100

k2_copy = kmeans(crime_cluster_copy, centers = 2)
fviz_cluster(k2_copy, data = crime_cluster_copy)

k3_copy = kmeans(crime_cluster_copy, centers = 3)
fviz_cluster(k3_copy, data = crime_cluster_copy)


fviz_nbclust(crime_cluster, kmeans, method = "silhouette")
fviz_nbclust(coordinate, kmeans, method = "silhouette")
k3 = kmeans(coordinate, centers = 3)
fviz_cluster(k3, data = coordinate)
```

```{r cluster analysis}
#create unique identifier variables for each charge
# CT_analysis_merged_cleaned_cluster$identifier <- NULL
# rownames(CT_analysis_merged_cleaned_cluster) <- CT_analysis_merged_cleaned$identifier

#conduct cluster analysis, excluding those with life sentences
CT_analysis_merged_cleaned_cluster <- CT_analysis_merged_cleaned %>% 
  ungroup() %>% 
  filter(life_sentence == 0) %>% 
  select(sentence_days, pretrial_detention_length, sentenced)

k1 <- kmeans(CT_analysis_merged_cleaned_cluster, centers = 3)

fviz_cluster(k1, data = CT_analysis_merged_cleaned_cluster)

```

```{r OLS regression analysis}

#run regression with sentenced as dependent variable
lm1 <- CT_analysis_merged_cleaned %>% 
  lm(sentenced ~ race.x +
                 as.factor(pretrial_offense) +
                 gender.x +
                 bond_amount +
                 pretrial_detention_length,
     data = .)

logit1 <- CT_analysis_merged_cleaned %>% 
  glm(sentenced ~ race.x +
                 as.factor(pretrial_offense) +
                 gender.x +
                 bond_amount +
                 pretrial_detention_length,
     family = "binomial",
     data = .)

summary(lm1)
summary(logit1)
```

